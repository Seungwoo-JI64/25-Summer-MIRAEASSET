{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f24c2a4",
   "metadata": {},
   "source": [
    "이곳에서는 기존의 clova x가 아닌 gemini를 사용하여 뉴스 영문 요약 및 임베딩 코드를 구축한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48c27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import create_client, Client\n",
    "import numpy as np\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec12ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'https://finance.yahoo.com/topic/latest-news/' 페이지에서 기사 목록을 수집하는 중...\n",
      "총 89개의 12시간 이내 기사를 찾았습니다.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "def parse_time_ago(time_str):\n",
    "    \"\"\"\n",
    "    'X minutes/hours ago' 형태의 시간 문자열을 파싱하여 timedelta 객체로 변환합니다.\n",
    "    예: \"Reuters•13 hours ago\" -> timedelta(hours=13)\n",
    "    \"\"\"\n",
    "    # \"Reuters•\" 같은 발행사 정보 제거\n",
    "    if '•' in time_str:\n",
    "        time_str = time_str.split('•')[1].strip()\n",
    "\n",
    "    # 정규표현식을 사용하여 숫자와 시간 단위(minute, hour)를 찾습니다.\n",
    "    match = re.search(r'(\\d+)\\s+(minute|hour)s?\\s+ago', time_str, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        value = int(match.group(1))\n",
    "        unit = match.group(2).lower()\n",
    "        \n",
    "        if unit == 'minute':\n",
    "            return timedelta(minutes=value)\n",
    "        elif unit == 'hour':\n",
    "            return timedelta(hours=value)\n",
    "            \n",
    "    return None\n",
    "\n",
    "def get_all_news_links(base_urls):\n",
    "    \"\"\"\n",
    "    주어진 모든 URL 페이지에서 12시간 이내에 작성된\n",
    "    모든 기사의 제목과 링크를 수집하고 중복을 제거합니다.\n",
    "    \"\"\"\n",
    "    # Selenium WebDriver 설정\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # 브라우저 창을 띄우지 않음\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    unique_articles = {}\n",
    "\n",
    "    for url in base_urls:\n",
    "        print(f\"'{url}' 페이지에서 기사 목록을 수집하는 중...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # WebDriverWait 객체 생성 (타임아웃 10초)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        \n",
    "        try:\n",
    "            # 페이지 로딩 대기: 최소 1개의 기사 아이템이 로드될 때까지\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"li.stream-item.story-item\")))\n",
    "        except TimeoutException:\n",
    "            print(f\"'{url}' 페이지에서 기사를 찾을 수 없거나 로딩에 실패했습니다.\")\n",
    "            continue\n",
    "\n",
    "        # 스크롤을 끝까지 내림\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            try:\n",
    "                # scrollHeight가 변경될 때까지 (최대 10초) 대기\n",
    "                wait.until(lambda d: d.execute_script(\"return document.body.scrollHeight\") > last_height)\n",
    "                # 새로운 높이로 업데이트\n",
    "                last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            except TimeoutException:\n",
    "                # 높이 변경이 없으면 더 이상 로드할 콘텐츠가 없는 것이므로 반복 종료\n",
    "                break\n",
    "\n",
    "        # 페이지 소스를 BeautifulSoup으로 파싱\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # 기사 목록 (li 태그) 찾기\n",
    "        news_list = soup.select('li.stream-item.story-item')\n",
    "\n",
    "        for item in news_list:\n",
    "            title_tag = item.select_one('h3')\n",
    "            link_tag = item.select_one('a.subtle-link')\n",
    "            # 발행 시간 정보를 담고 있는 div 태그 선택\n",
    "            time_tag = item.select_one('div.publishing')\n",
    "\n",
    "            if title_tag and link_tag and link_tag.has_attr('href') and time_tag:\n",
    "                time_str = time_tag.get_text(strip=True)\n",
    "                \n",
    "                # 발행 시간을 파싱\n",
    "                time_delta = parse_time_ago(time_str)\n",
    "                \n",
    "                # 파싱에 성공했고, 12시간 이내인 경우에만 추가\n",
    "                if time_delta and time_delta <= timedelta(hours=12):\n",
    "                    title = title_tag.get_text(strip=True)\n",
    "                    link = \"https://finance.yahoo.com\" + link_tag['href']\n",
    "\n",
    "                    # 제목을 기준으로 중복 제거\n",
    "                    if title not in unique_articles:\n",
    "                        unique_articles[title] = {\"url\": link, \"time\": time_str}\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    # 결과를 리스트 형태로 변환\n",
    "    article_list = [{\"title\": title, \"url\": data[\"url\"], \"time\": data[\"time\"]} for title, data in unique_articles.items()]\n",
    "    print(f\"총 {len(article_list)}개의 12시간 이내 기사를 찾았습니다.\")\n",
    "    return article_list\n",
    "\n",
    "# 대상 URL 목록\n",
    "target_urls = [\n",
    "    \"https://finance.yahoo.com/topic/latest-news/\",\n",
    "    # \"https://finance.yahoo.com/topic/stock-market-news/\",\n",
    "    # \"https://finance.yahoo.com/topic/yahoo-finance-originals/\",\n",
    "    # \"https://finance.yahoo.com/topic/economic-news/\",\n",
    "    # \"https://finance.yahoo.com/topic/earnings/\",\n",
    "    # \"https://finance.yahoo.com/topic/tech/\",\n",
    "    # \"https://finance.yahoo.com/topic/electric-vehicles/\"\n",
    "]\n",
    "\n",
    "# 함수 실행\n",
    "news_list = get_all_news_links(target_urls)\n",
    "\n",
    "# # 수집된 목록 일부 확인\n",
    "# print(\"\\n--- 수집된 뉴스 목록 (상위 5개) ---\")\n",
    "# for news in news_list[:5]:\n",
    "#     print(f\"제목: {news['title']}\")\n",
    "#     print(f\"URL: {news['url']}\")\n",
    "#     print(f\"발행시간: {news['time']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e859cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목: Renault set to name interim CEO next week, FT reports\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/renault-set-name-interim-ceo-040706230.html\n",
      "\n",
      "제목: Trump has delayed his monster tariffs. Here’s why you should care\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/trump-delayed-monster-tariffs-why-040125296.html\n",
      "\n",
      "제목: AP Top Extended Financial Headlines at 12:48 a.m. EDT\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/ap-top-extended-financial-headlines-040000354.html\n",
      "\n",
      "제목: AP Top Financial News at 12:48 a.m. EDT\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/ap-top-financial-news-12-040000759.html\n",
      "\n",
      "제목: REUTERS NEXT-Markets becoming desensitised to Trump's tariff shifts, CGS International CEO says\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/reuters-next-global-markets-becoming-031750086.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for news in news_list[:5]:\n",
    "    print(f\"제목: {news['title']}\")\n",
    "    print(f\"URL: {news['url']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8150d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list=news_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c9c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/5) 'Renault set to name interim CEO next week, FT reports' 기사 처리 중...\n",
      "(2/5) 'Trump has delayed his monster tariffs. Here’s why you should care' 기사 처리 중...\n",
      "(3/5) 'AP Top Extended Financial Headlines at 12:48 a.m. EDT' 기사 처리 중...\n",
      "(4/5) 'AP Top Financial News at 12:48 a.m. EDT' 기사 처리 중...\n",
      "(5/5) 'REUTERS NEXT-Markets becoming desensitised to Trump's tariff shifts, CGS International CEO says' 기사 처리 중...\n",
      "\n",
      "--- 최종 수집 데이터 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Renault set to name interim CEO next week, FT ...</td>\n",
       "      <td>2025-07-09 13:07:00</td>\n",
       "      <td>https://finance.yahoo.com/news/renault-set-nam...</td>\n",
       "      <td>(Reuters) -Renault will name an interim CEO ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump has delayed his monster tariffs. Here’s ...</td>\n",
       "      <td>2025-07-09 13:01:00</td>\n",
       "      <td>https://finance.yahoo.com/news/trump-delayed-m...</td>\n",
       "      <td>Shipping containers at the port of Houston in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP Top Extended Financial Headlines at 12:48 a...</td>\n",
       "      <td>2025-07-09 13:00:00</td>\n",
       "      <td>https://finance.yahoo.com/news/ap-top-extended...</td>\n",
       "      <td>President Donald Trump has sent letters to 14 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP Top Financial News at 12:48 a.m. EDT</td>\n",
       "      <td>2025-07-09 13:00:00</td>\n",
       "      <td>https://finance.yahoo.com/news/ap-top-financia...</td>\n",
       "      <td>A look at the countries that received Trump's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REUTERS NEXT-Markets becoming desensitised to ...</td>\n",
       "      <td>2025-07-09 12:17:00</td>\n",
       "      <td>https://finance.yahoo.com/news/reuters-next-gl...</td>\n",
       "      <td>By Yantoultra Ngui, Jun Yuan Yong and Himanshi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        publish_date  \\\n",
       "0  Renault set to name interim CEO next week, FT ... 2025-07-09 13:07:00   \n",
       "1  Trump has delayed his monster tariffs. Here’s ... 2025-07-09 13:01:00   \n",
       "2  AP Top Extended Financial Headlines at 12:48 a... 2025-07-09 13:00:00   \n",
       "3            AP Top Financial News at 12:48 a.m. EDT 2025-07-09 13:00:00   \n",
       "4  REUTERS NEXT-Markets becoming desensitised to ... 2025-07-09 12:17:00   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://finance.yahoo.com/news/renault-set-nam...   \n",
       "1  https://finance.yahoo.com/news/trump-delayed-m...   \n",
       "2  https://finance.yahoo.com/news/ap-top-extended...   \n",
       "3  https://finance.yahoo.com/news/ap-top-financia...   \n",
       "4  https://finance.yahoo.com/news/reuters-next-gl...   \n",
       "\n",
       "                                             content  \n",
       "0  (Reuters) -Renault will name an interim CEO ne...  \n",
       "1  Shipping containers at the port of Houston in ...  \n",
       "2  President Donald Trump has sent letters to 14 ...  \n",
       "3  A look at the countries that received Trump's ...  \n",
       "4  By Yantoultra Ngui, Jun Yuan Yong and Himanshi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "\n",
    "def get_article_details(article_list):\n",
    "    \"\"\"\n",
    "    뉴스 목록을 받아 각 기사의 본문과 게시 날짜를 추출합니다.\n",
    "    429 오류 발생 시 재시도 로직을 포함합니다.\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "    \n",
    "    for i, article in enumerate(article_list):\n",
    "        print(f\"({i+1}/{len(article_list)}) '{article['title']}' 기사 처리 중...\")\n",
    "        \n",
    "        # --- 오류 수정 부분 ---\n",
    "        url_to_fetch = article['url']\n",
    "        if url_to_fetch.count('https://finance.yahoo.com') > 1:\n",
    "            url_to_fetch = 'https://finance.yahoo.com' + url_to_fetch.split('https://finance.yahoo.com')[-1]\n",
    "        \n",
    "        retries = 3\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(url_to_fetch, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # 1. 본문 추출\n",
    "                content_parts = []\n",
    "                body_wrappers = soup.select('div.atoms-wrapper, div.read-more-wrapper')\n",
    "                for wrapper in body_wrappers:\n",
    "                    content_parts.append(wrapper.get_text(separator=' ', strip=True))\n",
    "                content = ' '.join(content_parts)\n",
    "\n",
    "                # 2. 게시 날짜 추출 및 형식 변환\n",
    "                time_tag = soup.select_one('time')\n",
    "                publish_date_str = \"N/A\"\n",
    "                if time_tag and time_tag.has_attr('datetime'):\n",
    "                    dt_object = parse(time_tag['datetime'])\n",
    "                    publish_date_str = dt_object.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "                # 결과 리스트에 추가\n",
    "                final_results.append({\n",
    "                    \"title\": article['title'],\n",
    "                    \"publish_date\": publish_date_str,\n",
    "                    \"url\": url_to_fetch,\n",
    "                    \"content\": content\n",
    "                })\n",
    "                \n",
    "                time.sleep(2) # 성공 시 요청 간격을 2초로 늘림\n",
    "                break # 성공했으므로 재시도 루프 탈출\n",
    "\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    wait_time = 10\n",
    "                    print(f\"  [알림] 429 오류 발생. {wait_time}초 후 재시도합니다... ({attempt + 1}/{retries})\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"  [오류] HTTP 오류 발생: {e}\")\n",
    "                    break # 다른 HTTP 오류는 재시도하지 않음\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"  [오류] 기사 접근 중 오류 발생: {e}\")\n",
    "                break # 일반적인 요청 오류는 재시도하지 않음\n",
    "            except Exception as e:\n",
    "                print(f\"  [오류] 기사 처리 중 예외 발생: {e}\")\n",
    "                break\n",
    "        else: # for 루프가 break 없이 끝났을 경우 (모든 재시도 실패)\n",
    "            print(f\"  [실패] 모든 재시도에 실패하여 다음 기사로 넘어갑니다.\")\n",
    "            \n",
    "    return final_results\n",
    "\n",
    "# 함수 실행\n",
    "# 이전에 생성된 news_list를 그대로 사용합니다.\n",
    "full_news_data = get_article_details(news_list)\n",
    "\n",
    "# 최종 결과 확인 (데이터프레임으로 변환하여 출력)\n",
    "df = pd.DataFrame(full_news_data)\n",
    "df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce') + pd.Timedelta(hours=9) # 한국 시간으로 변환 UTC+9\n",
    "print(\"\\n--- 최종 수집 데이터 ---\")\n",
    "display(df.head())\n",
    "\n",
    "# CSV 파일로 저장 (선택 사항)\n",
    "# df.to_csv('yahoo_finance_news.csv', index=False, encoding='utf-8-sig')\n",
    "# print(\"\\n'yahoo_finance_news.csv' 파일로 저장이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe00542",
   "metadata": {},
   "source": [
    "AIzaSyDkYM__gE0UyegX2-6BUaxjj7PivCPchk8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title        publish_date  \\\n",
      "0  Renault set to name interim CEO next week, FT ... 2025-07-09 13:07:00   \n",
      "1  Trump has delayed his monster tariffs. Here’s ... 2025-07-09 13:01:00   \n",
      "2  AP Top Extended Financial Headlines at 12:48 a... 2025-07-09 13:00:00   \n",
      "3            AP Top Financial News at 12:48 a.m. EDT 2025-07-09 13:00:00   \n",
      "4  REUTERS NEXT-Markets becoming desensitised to ... 2025-07-09 12:17:00   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://finance.yahoo.com/news/renault-set-nam...   \n",
      "1  https://finance.yahoo.com/news/trump-delayed-m...   \n",
      "2  https://finance.yahoo.com/news/ap-top-extended...   \n",
      "3  https://finance.yahoo.com/news/ap-top-financia...   \n",
      "4  https://finance.yahoo.com/news/reuters-next-gl...   \n",
      "\n",
      "                                             content  \\\n",
      "0  (Reuters) -Renault will name an interim CEO ne...   \n",
      "1  Shipping containers at the port of Houston in ...   \n",
      "2  President Donald Trump has sent letters to 14 ...   \n",
      "3  A look at the countries that received Trump's ...   \n",
      "4  By Yantoultra Ngui, Jun Yuan Yong and Himanshi...   \n",
      "\n",
      "                                             summary  \n",
      "0  Renault is preparing to name an interim CEO ne...  \n",
      "1  President Trump's \"reciprocal\" tariffs have be...  \n",
      "2  President Donald Trump has notified 14 countri...  \n",
      "3  To provide an expert analysis and a three-sent...  \n",
      "4  Global financial markets are reportedly becomi...  \n"
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리 설치\n",
    "# pip install google-generai pandas\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# --- 여기에 API 키를 직접 입력하세요 ---\n",
    "API_KEY = \"AIzaSyDkYM__gE0UyegX2-6BUaxjj7PivCPchk8\" \n",
    "\n",
    "def analyze_news_article(article_text: str, api_key: str) -> str:\n",
    "    \"\"\"\n",
    "    하나의 뉴스 기사 텍스트를 받아 Gemini API로 분석하고 결과를 반환하는 함수.\n",
    "    보내주신 공식 예제 구조를 그대로 따릅니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. genai.Client를 사용하여 클라이언트를 생성합니다.\n",
    "        client = genai.Client(api_key=api_key)\n",
    "\n",
    "        # 2. 모델 이름을 요청하신 그대로 \"gemini-2.5-flash\"로 설정합니다.\n",
    "        model = \"gemini-2.5-flash\"\n",
    "        \n",
    "        # 3. types.Content와 types.Part를 사용하여 대화 내용을 구성합니다.\n",
    "        contents = [\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part.from_text(text=\"\"\"You are an expert stock analyst. Your task is to analyze an English news article and provide a summary.\n",
    "\n",
    "### INSTRUCTIONS ###\n",
    "1.  Analyze the provided English news article for key information relevant to investors (e.g., corporate earnings, new products, M&A, regulatory changes).\n",
    "2.  Create a three-sentence summary in English.\n",
    "3.  The summary must explicitly state whether the nuance of the news is positive, negative, or neutral for investors.\n",
    "\n",
    "### EXAMPLES & BEHAVIORAL RULES ###\n",
    "This is an example of how to behave.\n",
    "\n",
    "**Example Scenario:** If the user provides instructions but no article to analyze below the \"---\" line.\n",
    "**Your Correct Response in this case is this plain text:**\n",
    "To provide an expert analysis and a three-sentence summary, the news article must be provided. Please submit the English news article for review, and I will extract the key investor-relevant information, determine the market nuance, and synthesize it into the requested format. Without the article, a specific analysis is not possible.\n",
    "\n",
    "---\n",
    "ARTICLE TO ANALYZE:\n",
    "---\n",
    "\n",
    "[여기에 분석할 영어 뉴스 기사를 붙여넣으세요]\"\"\"),\n",
    "            ],\n",
    "            ),\n",
    "            types.Content(\n",
    "                role=\"model\",\n",
    "                parts=[\n",
    "                    types.Part.from_text(text=\"\"\"{\"summary\": \"Understood. I am ready to analyze the provided news article.\"}\"\"\"),\n",
    "                ],\n",
    "            ),\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    # 함수 인자로 받은 뉴스 기사를 여기에 삽입합니다.\n",
    "                    types.Part.from_text(text=article_text),\n",
    "                ],\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        # 4. client.models.generate_content_stream을 호출하여 결과를 스트리밍합니다.\n",
    "        response_chunks = []\n",
    "        for chunk in client.models.generate_content_stream(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "        ):\n",
    "            response_chunks.append(chunk.text)\n",
    "        \n",
    "        return \"\".join(response_chunks)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return '{\"summary\": \"Error during analysis.\"}'\n",
    "\n",
    "\n",
    "# --- 메인 실행 부분 ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df['summary'] = df['content'].apply(lambda content: analyze_news_article(content, api_key=API_KEY))\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "313b65f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title        publish_date  \\\n",
      "0  Renault set to name interim CEO next week, FT ... 2025-07-09 13:07:00   \n",
      "1  Trump has delayed his monster tariffs. Here’s ... 2025-07-09 13:01:00   \n",
      "2  AP Top Extended Financial Headlines at 12:48 a... 2025-07-09 13:00:00   \n",
      "3            AP Top Financial News at 12:48 a.m. EDT 2025-07-09 13:00:00   \n",
      "4  REUTERS NEXT-Markets becoming desensitised to ... 2025-07-09 12:17:00   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://finance.yahoo.com/news/renault-set-nam...   \n",
      "1  https://finance.yahoo.com/news/trump-delayed-m...   \n",
      "2  https://finance.yahoo.com/news/ap-top-extended...   \n",
      "3  https://finance.yahoo.com/news/ap-top-financia...   \n",
      "4  https://finance.yahoo.com/news/reuters-next-gl...   \n",
      "\n",
      "                                             content  \\\n",
      "0  (Reuters) -Renault will name an interim CEO ne...   \n",
      "1  Shipping containers at the port of Houston in ...   \n",
      "2  President Donald Trump has sent letters to 14 ...   \n",
      "3  A look at the countries that received Trump's ...   \n",
      "4  By Yantoultra Ngui, Jun Yuan Yong and Himanshi...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  Renault is preparing to name an interim CEO ne...   \n",
      "1  President Trump's \"reciprocal\" tariffs have be...   \n",
      "2  President Donald Trump has notified 14 countri...   \n",
      "3  To provide an expert analysis and a three-sent...   \n",
      "4  Global financial markets are reportedly becomi...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [0.022992134, -0.04607002, -0.008888895, -0.00...  \n",
      "1  [0.017440025, -0.029061683, -0.009535746, -0.0...  \n",
      "2  [0.023037886, -0.057103354, -0.038891286, -0.0...  \n",
      "3  [0.03301442, -0.001232819, -0.04580554, -0.020...  \n",
      "4  [0.0029243096, -0.014824337, -0.055987753, -0....  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google import genai\n",
    "import os\n",
    "\n",
    "# --- 여기에 API 키를 직접 입력하세요 ---\n",
    "API_KEY = \"AIzaSyDkYM__gE0UyegX2-6BUaxjj7PivCPchk8\" \n",
    "\n",
    "def get_summary_embedding(summary_text: str, client: genai.Client) -> list[float] | None:\n",
    "    \"\"\"\n",
    "    하나의 요약본 텍스트를 받아 임베딩 벡터를 반환하는 함수.\n",
    "    \"\"\"\n",
    "    # 1. 요약본 내용이 비어있는지 확인\n",
    "    if not summary_text or pd.isna(summary_text):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 2. 'contents'가 아닌 'content' 파라미터로 단일 텍스트를 전달\n",
    "        result = client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=summary_text,\n",
    "            config=types.EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")\n",
    "        )\n",
    "        # 3. 결과 객체에서 .embedding 속성으로 벡터를 직접 반환\n",
    "        vectors = [obj.values for obj in result.embeddings]\n",
    "        vectors=vectors[0]\n",
    "\n",
    "        return vectors\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API Error embedding '{summary_text[:50]}...': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- 메인 실행 부분 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 클라이언트는 한 번만 생성합니다.\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    df['embedding'] = df['summary'].apply(lambda text: get_summary_embedding(text, client))\n",
    "\n",
    "    # 최종 결과 확인\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6895c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# 1. 여기에 복사한 URL과 Key를 붙여넣으세요.\n",
    "supabase_url = \"https://hcmniqyaqybzhmzmaumh.supabase.co\"\n",
    "supabase_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImhjbW5pcXlhcXliemhtem1hdW1oIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTE0Mzk5NDgsImV4cCI6MjA2NzAxNTk0OH0.wj3P2BaI9_9LjXPULyKIYja20Xk3TbuqS916Sw83Pdg\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ba22075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☁️ Supabase에 연결하여 기존 데이터를 확인합니다.\n",
      "현재 DB에 0개의 기사가 있습니다.\n",
      "✨ 5개의 새로운 기사를 찾았습니다. 업로드를 준비합니다.\n",
      "🎉 성공적으로 5개의 새 기사를 업로드했습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    supabase: Client = create_client(supabase_url, supabase_key)\n",
    "    print(\"☁️ Supabase에 연결하여 기존 데이터를 확인합니다.\")\n",
    "\n",
    "    # DB에 저장된 모든 'title' 목록을 가져오기\n",
    "    response = supabase.table('financial_news_summary').select('title').execute()\n",
    "    existing_titles = {item['title'] for item in response.data}\n",
    "    print(f\"현재 DB에 {len(existing_titles)}개의 기사가 있습니다.\")\n",
    "\n",
    "    # 새로 생성된 DataFrame에서 이미 있는 title들을 제외\n",
    "    new_articles_df = df[~df['title'].isin(existing_titles)]\n",
    "\n",
    "    if new_articles_df.empty:\n",
    "        print(\"✅ 추가할 새로운 기사가 없습니다.\")\n",
    "    else:\n",
    "        print(f\"✨ {len(new_articles_df)}개의 새로운 기사를 찾았습니다. 업로드를 준비합니다.\")\n",
    "\n",
    "    \n",
    "        # 업로드 형식으로 변환\n",
    "        records_to_upload = new_articles_df.to_dict('records')\n",
    "        for record in records_to_upload:\n",
    "            record['publish_date'] = record['publish_date'].isoformat()\n",
    "        \n",
    "        # 데이터 삽입\n",
    "        data, count = supabase.table('financial_news_summary').insert(records_to_upload).execute()\n",
    "        print(f\"🎉 성공적으로 {len(data[1])}개의 새 기사를 업로드했습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 작업 중 오류 발생: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
