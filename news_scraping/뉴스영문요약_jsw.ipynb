{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f24c2a4",
   "metadata": {},
   "source": [
    "ì´ê³³ì—ì„œëŠ” ê¸°ì¡´ì˜ clova xê°€ ì•„ë‹Œ geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ì˜ë¬¸ ìš”ì•½ ë° ì„ë² ë”© ì½”ë“œë¥¼ êµ¬ì¶•í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48c27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import create_client, Client\n",
    "import numpy as np\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec12ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'https://finance.yahoo.com/topic/latest-news/' í˜ì´ì§€ì—ì„œ ê¸°ì‚¬ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ëŠ” ì¤‘...\n",
      "ì´ 89ê°œì˜ 12ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "def parse_time_ago(time_str):\n",
    "    \"\"\"\n",
    "    'X minutes/hours ago' í˜•íƒœì˜ ì‹œê°„ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ timedelta ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    ì˜ˆ: \"Reutersâ€¢13 hours ago\" -> timedelta(hours=13)\n",
    "    \"\"\"\n",
    "    # \"Reutersâ€¢\" ê°™ì€ ë°œí–‰ì‚¬ ì •ë³´ ì œê±°\n",
    "    if 'â€¢' in time_str:\n",
    "        time_str = time_str.split('â€¢')[1].strip()\n",
    "\n",
    "    # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ìˆ«ìì™€ ì‹œê°„ ë‹¨ìœ„(minute, hour)ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    match = re.search(r'(\\d+)\\s+(minute|hour)s?\\s+ago', time_str, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        value = int(match.group(1))\n",
    "        unit = match.group(2).lower()\n",
    "        \n",
    "        if unit == 'minute':\n",
    "            return timedelta(minutes=value)\n",
    "        elif unit == 'hour':\n",
    "            return timedelta(hours=value)\n",
    "            \n",
    "    return None\n",
    "\n",
    "def get_all_news_links(base_urls):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ëª¨ë“  URL í˜ì´ì§€ì—ì„œ 12ì‹œê°„ ì´ë‚´ì— ì‘ì„±ëœ\n",
    "    ëª¨ë“  ê¸°ì‚¬ì˜ ì œëª©ê³¼ ë§í¬ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # Selenium WebDriver ì„¤ì •\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # ë¸Œë¼ìš°ì € ì°½ì„ ë„ìš°ì§€ ì•ŠìŒ\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    unique_articles = {}\n",
    "\n",
    "    for url in base_urls:\n",
    "        print(f\"'{url}' í˜ì´ì§€ì—ì„œ ê¸°ì‚¬ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ëŠ” ì¤‘...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # WebDriverWait ê°ì²´ ìƒì„± (íƒ€ì„ì•„ì›ƒ 10ì´ˆ)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        \n",
    "        try:\n",
    "            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°: ìµœì†Œ 1ê°œì˜ ê¸°ì‚¬ ì•„ì´í…œì´ ë¡œë“œë  ë•Œê¹Œì§€\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"li.stream-item.story-item\")))\n",
    "        except TimeoutException:\n",
    "            print(f\"'{url}' í˜ì´ì§€ì—ì„œ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            continue\n",
    "\n",
    "        # ìŠ¤í¬ë¡¤ì„ ëê¹Œì§€ ë‚´ë¦¼\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            try:\n",
    "                # scrollHeightê°€ ë³€ê²½ë  ë•Œê¹Œì§€ (ìµœëŒ€ 10ì´ˆ) ëŒ€ê¸°\n",
    "                wait.until(lambda d: d.execute_script(\"return document.body.scrollHeight\") > last_height)\n",
    "                # ìƒˆë¡œìš´ ë†’ì´ë¡œ ì—…ë°ì´íŠ¸\n",
    "                last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            except TimeoutException:\n",
    "                # ë†’ì´ ë³€ê²½ì´ ì—†ìœ¼ë©´ ë” ì´ìƒ ë¡œë“œí•  ì½˜í…ì¸ ê°€ ì—†ëŠ” ê²ƒì´ë¯€ë¡œ ë°˜ë³µ ì¢…ë£Œ\n",
    "                break\n",
    "\n",
    "        # í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ BeautifulSoupìœ¼ë¡œ íŒŒì‹±\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # ê¸°ì‚¬ ëª©ë¡ (li íƒœê·¸) ì°¾ê¸°\n",
    "        news_list = soup.select('li.stream-item.story-item')\n",
    "\n",
    "        for item in news_list:\n",
    "            title_tag = item.select_one('h3')\n",
    "            link_tag = item.select_one('a.subtle-link')\n",
    "            # ë°œí–‰ ì‹œê°„ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” div íƒœê·¸ ì„ íƒ\n",
    "            time_tag = item.select_one('div.publishing')\n",
    "\n",
    "            if title_tag and link_tag and link_tag.has_attr('href') and time_tag:\n",
    "                time_str = time_tag.get_text(strip=True)\n",
    "                \n",
    "                # ë°œí–‰ ì‹œê°„ì„ íŒŒì‹±\n",
    "                time_delta = parse_time_ago(time_str)\n",
    "                \n",
    "                # íŒŒì‹±ì— ì„±ê³µí–ˆê³ , 12ì‹œê°„ ì´ë‚´ì¸ ê²½ìš°ì—ë§Œ ì¶”ê°€\n",
    "                if time_delta and time_delta <= timedelta(hours=12):\n",
    "                    title = title_tag.get_text(strip=True)\n",
    "                    link = \"https://finance.yahoo.com\" + link_tag['href']\n",
    "\n",
    "                    # ì œëª©ì„ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°\n",
    "                    if title not in unique_articles:\n",
    "                        unique_articles[title] = {\"url\": link, \"time\": time_str}\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜\n",
    "    article_list = [{\"title\": title, \"url\": data[\"url\"], \"time\": data[\"time\"]} for title, data in unique_articles.items()]\n",
    "    print(f\"ì´ {len(article_list)}ê°œì˜ 12ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    return article_list\n",
    "\n",
    "# ëŒ€ìƒ URL ëª©ë¡\n",
    "target_urls = [\n",
    "    \"https://finance.yahoo.com/topic/latest-news/\",\n",
    "    # \"https://finance.yahoo.com/topic/stock-market-news/\",\n",
    "    # \"https://finance.yahoo.com/topic/yahoo-finance-originals/\",\n",
    "    # \"https://finance.yahoo.com/topic/economic-news/\",\n",
    "    # \"https://finance.yahoo.com/topic/earnings/\",\n",
    "    # \"https://finance.yahoo.com/topic/tech/\",\n",
    "    # \"https://finance.yahoo.com/topic/electric-vehicles/\"\n",
    "]\n",
    "\n",
    "# í•¨ìˆ˜ ì‹¤í–‰\n",
    "news_list = get_all_news_links(target_urls)\n",
    "\n",
    "# # ìˆ˜ì§‘ëœ ëª©ë¡ ì¼ë¶€ í™•ì¸\n",
    "# print(\"\\n--- ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡ (ìƒìœ„ 5ê°œ) ---\")\n",
    "# for news in news_list[:5]:\n",
    "#     print(f\"ì œëª©: {news['title']}\")\n",
    "#     print(f\"URL: {news['url']}\")\n",
    "#     print(f\"ë°œí–‰ì‹œê°„: {news['time']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e859cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œëª©: Renault set to name interim CEO next week, FT reports\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/renault-set-name-interim-ceo-040706230.html\n",
      "\n",
      "ì œëª©: Trump has delayed his monster tariffs. Hereâ€™s why you should care\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/trump-delayed-monster-tariffs-why-040125296.html\n",
      "\n",
      "ì œëª©: AP Top Extended Financial Headlines at 12:48 a.m. EDT\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/ap-top-extended-financial-headlines-040000354.html\n",
      "\n",
      "ì œëª©: AP Top Financial News at 12:48 a.m. EDT\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/ap-top-financial-news-12-040000759.html\n",
      "\n",
      "ì œëª©: REUTERS NEXT-Markets becoming desensitised to Trump's tariff shifts, CGS International CEO says\n",
      "URL: https://finance.yahoo.comhttps://finance.yahoo.com/news/reuters-next-global-markets-becoming-031750086.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for news in news_list[:5]:\n",
    "    print(f\"ì œëª©: {news['title']}\")\n",
    "    print(f\"URL: {news['url']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8150d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list=news_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c9c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/5) 'Renault set to name interim CEO next week, FT reports' ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘...\n",
      "(2/5) 'Trump has delayed his monster tariffs. Hereâ€™s why you should care' ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘...\n",
      "(3/5) 'AP Top Extended Financial Headlines at 12:48 a.m. EDT' ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘...\n",
      "(4/5) 'AP Top Financial News at 12:48 a.m. EDT' ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘...\n",
      "(5/5) 'REUTERS NEXT-Markets becoming desensitised to Trump's tariff shifts, CGS International CEO says' ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "--- ìµœì¢… ìˆ˜ì§‘ ë°ì´í„° ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Renault set to name interim CEO next week, FT ...</td>\n",
       "      <td>2025-07-09 13:07:00</td>\n",
       "      <td>https://finance.yahoo.com/news/renault-set-nam...</td>\n",
       "      <td>(Reuters) -Renault will name an interim CEO ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump has delayed his monster tariffs. Hereâ€™s ...</td>\n",
       "      <td>2025-07-09 13:01:00</td>\n",
       "      <td>https://finance.yahoo.com/news/trump-delayed-m...</td>\n",
       "      <td>Shipping containers at the port of Houston in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP Top Extended Financial Headlines at 12:48 a...</td>\n",
       "      <td>2025-07-09 13:00:00</td>\n",
       "      <td>https://finance.yahoo.com/news/ap-top-extended...</td>\n",
       "      <td>President Donald Trump has sent letters to 14 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP Top Financial News at 12:48 a.m. EDT</td>\n",
       "      <td>2025-07-09 13:00:00</td>\n",
       "      <td>https://finance.yahoo.com/news/ap-top-financia...</td>\n",
       "      <td>A look at the countries that received Trump's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REUTERS NEXT-Markets becoming desensitised to ...</td>\n",
       "      <td>2025-07-09 12:17:00</td>\n",
       "      <td>https://finance.yahoo.com/news/reuters-next-gl...</td>\n",
       "      <td>By Yantoultra Ngui, Jun Yuan Yong and Himanshi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        publish_date  \\\n",
       "0  Renault set to name interim CEO next week, FT ... 2025-07-09 13:07:00   \n",
       "1  Trump has delayed his monster tariffs. Hereâ€™s ... 2025-07-09 13:01:00   \n",
       "2  AP Top Extended Financial Headlines at 12:48 a... 2025-07-09 13:00:00   \n",
       "3            AP Top Financial News at 12:48 a.m. EDT 2025-07-09 13:00:00   \n",
       "4  REUTERS NEXT-Markets becoming desensitised to ... 2025-07-09 12:17:00   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://finance.yahoo.com/news/renault-set-nam...   \n",
       "1  https://finance.yahoo.com/news/trump-delayed-m...   \n",
       "2  https://finance.yahoo.com/news/ap-top-extended...   \n",
       "3  https://finance.yahoo.com/news/ap-top-financia...   \n",
       "4  https://finance.yahoo.com/news/reuters-next-gl...   \n",
       "\n",
       "                                             content  \n",
       "0  (Reuters) -Renault will name an interim CEO ne...  \n",
       "1  Shipping containers at the port of Houston in ...  \n",
       "2  President Donald Trump has sent letters to 14 ...  \n",
       "3  A look at the countries that received Trump's ...  \n",
       "4  By Yantoultra Ngui, Jun Yuan Yong and Himanshi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "\n",
    "def get_article_details(article_list):\n",
    "    \"\"\"\n",
    "    ë‰´ìŠ¤ ëª©ë¡ì„ ë°›ì•„ ê° ê¸°ì‚¬ì˜ ë³¸ë¬¸ê³¼ ê²Œì‹œ ë‚ ì§œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    429 ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "    \n",
    "    for i, article in enumerate(article_list):\n",
    "        print(f\"({i+1}/{len(article_list)}) '{article['title']}' ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # --- ì˜¤ë¥˜ ìˆ˜ì • ë¶€ë¶„ ---\n",
    "        url_to_fetch = article['url']\n",
    "        if url_to_fetch.count('https://finance.yahoo.com') > 1:\n",
    "            url_to_fetch = 'https://finance.yahoo.com' + url_to_fetch.split('https://finance.yahoo.com')[-1]\n",
    "        \n",
    "        retries = 3\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(url_to_fetch, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # 1. ë³¸ë¬¸ ì¶”ì¶œ\n",
    "                content_parts = []\n",
    "                body_wrappers = soup.select('div.atoms-wrapper, div.read-more-wrapper')\n",
    "                for wrapper in body_wrappers:\n",
    "                    content_parts.append(wrapper.get_text(separator=' ', strip=True))\n",
    "                content = ' '.join(content_parts)\n",
    "\n",
    "                # 2. ê²Œì‹œ ë‚ ì§œ ì¶”ì¶œ ë° í˜•ì‹ ë³€í™˜\n",
    "                time_tag = soup.select_one('time')\n",
    "                publish_date_str = \"N/A\"\n",
    "                if time_tag and time_tag.has_attr('datetime'):\n",
    "                    dt_object = parse(time_tag['datetime'])\n",
    "                    publish_date_str = dt_object.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "                # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "                final_results.append({\n",
    "                    \"title\": article['title'],\n",
    "                    \"publish_date\": publish_date_str,\n",
    "                    \"url\": url_to_fetch,\n",
    "                    \"content\": content\n",
    "                })\n",
    "                \n",
    "                time.sleep(2) # ì„±ê³µ ì‹œ ìš”ì²­ ê°„ê²©ì„ 2ì´ˆë¡œ ëŠ˜ë¦¼\n",
    "                break # ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ\n",
    "\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 429:\n",
    "                    wait_time = 10\n",
    "                    print(f\"  [ì•Œë¦¼] 429 ì˜¤ë¥˜ ë°œìƒ. {wait_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤... ({attempt + 1}/{retries})\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"  [ì˜¤ë¥˜] HTTP ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "                    break # ë‹¤ë¥¸ HTTP ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"  [ì˜¤ë¥˜] ê¸°ì‚¬ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "                break # ì¼ë°˜ì ì¸ ìš”ì²­ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ\n",
    "            except Exception as e:\n",
    "                print(f\"  [ì˜¤ë¥˜] ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}\")\n",
    "                break\n",
    "        else: # for ë£¨í”„ê°€ break ì—†ì´ ëë‚¬ì„ ê²½ìš° (ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨)\n",
    "            print(f\"  [ì‹¤íŒ¨] ëª¨ë“  ì¬ì‹œë„ì— ì‹¤íŒ¨í•˜ì—¬ ë‹¤ìŒ ê¸°ì‚¬ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\")\n",
    "            \n",
    "    return final_results\n",
    "\n",
    "# í•¨ìˆ˜ ì‹¤í–‰\n",
    "# ì´ì „ì— ìƒì„±ëœ news_listë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "full_news_data = get_article_details(news_list)\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ í™•ì¸ (ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥)\n",
    "df = pd.DataFrame(full_news_data)\n",
    "df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce') + pd.Timedelta(hours=9) # í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ UTC+9\n",
    "print(\"\\n--- ìµœì¢… ìˆ˜ì§‘ ë°ì´í„° ---\")\n",
    "display(df.head())\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒ ì‚¬í•­)\n",
    "# df.to_csv('yahoo_finance_news.csv', index=False, encoding='utf-8-sig')\n",
    "# print(\"\\n'yahoo_finance_news.csv' íŒŒì¼ë¡œ ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe00542",
   "metadata": {},
   "source": [
    "AIzaSyDkYM__gE0UyegX2-6BUaxjj7PivCPchk8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title        publish_date  \\\n",
      "0  Renault set to name interim CEO next week, FT ... 2025-07-09 13:07:00   \n",
      "1  Trump has delayed his monster tariffs. Hereâ€™s ... 2025-07-09 13:01:00   \n",
      "2  AP Top Extended Financial Headlines at 12:48 a... 2025-07-09 13:00:00   \n",
      "3            AP Top Financial News at 12:48 a.m. EDT 2025-07-09 13:00:00   \n",
      "4  REUTERS NEXT-Markets becoming desensitised to ... 2025-07-09 12:17:00   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://finance.yahoo.com/news/renault-set-nam...   \n",
      "1  https://finance.yahoo.com/news/trump-delayed-m...   \n",
      "2  https://finance.yahoo.com/news/ap-top-extended...   \n",
      "3  https://finance.yahoo.com/news/ap-top-financia...   \n",
      "4  https://finance.yahoo.com/news/reuters-next-gl...   \n",
      "\n",
      "                                             content  \\\n",
      "0  (Reuters) -Renault will name an interim CEO ne...   \n",
      "1  Shipping containers at the port of Houston in ...   \n",
      "2  President Donald Trump has sent letters to 14 ...   \n",
      "3  A look at the countries that received Trump's ...   \n",
      "4  By Yantoultra Ngui, Jun Yuan Yong and Himanshi...   \n",
      "\n",
      "                                             summary  \n",
      "0  Renault is preparing to name an interim CEO ne...  \n",
      "1  President Trump's \"reciprocal\" tariffs have be...  \n",
      "2  President Donald Trump has notified 14 countri...  \n",
      "3  To provide an expert analysis and a three-sent...  \n",
      "4  Global financial markets are reportedly becomi...  \n"
     ]
    }
   ],
   "source": [
    "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# pip install google-generai pandas\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# --- ì—¬ê¸°ì— API í‚¤ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš” ---\n",
    "API_KEY = \"AIzaSyDkYM__gE0UyegX2-6BUaxjj7PivCPchk8\" \n",
    "\n",
    "def analyze_news_article(article_text: str, api_key: str) -> str:\n",
    "    \"\"\"\n",
    "    í•˜ë‚˜ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ Gemini APIë¡œ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
    "    ë³´ë‚´ì£¼ì‹  ê³µì‹ ì˜ˆì œ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¦…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. genai.Clientë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        client = genai.Client(api_key=api_key)\n",
    "\n",
    "        # 2. ëª¨ë¸ ì´ë¦„ì„ ìš”ì²­í•˜ì‹  ê·¸ëŒ€ë¡œ \"gemini-2.5-flash\"ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "        model = \"gemini-2.5-flash\"\n",
    "        \n",
    "        # 3. types.Contentì™€ types.Partë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš©ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "        contents = [\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part.from_text(text=\"\"\"You are an expert stock analyst. Your task is to analyze an English news article and provide a summary.\n",
    "\n",
    "### INSTRUCTIONS ###\n",
    "1.  Analyze the provided English news article for key information relevant to investors (e.g., corporate earnings, new products, M&A, regulatory changes).\n",
    "2.  Create a three-sentence summary in English.\n",
    "3.  The summary must explicitly state whether the nuance of the news is positive, negative, or neutral for investors.\n",
    "\n",
    "### EXAMPLES & BEHAVIORAL RULES ###\n",
    "This is an example of how to behave.\n",
    "\n",
    "**Example Scenario:** If the user provides instructions but no article to analyze below the \"---\" line.\n",
    "**Your Correct Response in this case is this plain text:**\n",
    "To provide an expert analysis and a three-sentence summary, the news article must be provided. Please submit the English news article for review, and I will extract the key investor-relevant information, determine the market nuance, and synthesize it into the requested format. Without the article, a specific analysis is not possible.\n",
    "\n",
    "---\n",
    "ARTICLE TO ANALYZE:\n",
    "---\n",
    "\n",
    "[ì—¬ê¸°ì— ë¶„ì„í•  ì˜ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”]\"\"\"),\n",
    "            ],\n",
    "            ),\n",
    "            types.Content(\n",
    "                role=\"model\",\n",
    "                parts=[\n",
    "                    types.Part.from_text(text=\"\"\"{\"summary\": \"Understood. I am ready to analyze the provided news article.\"}\"\"\"),\n",
    "                ],\n",
    "            ),\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    # í•¨ìˆ˜ ì¸ìë¡œ ë°›ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì—¬ê¸°ì— ì‚½ì…í•©ë‹ˆë‹¤.\n",
    "                    types.Part.from_text(text=article_text),\n",
    "                ],\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        # 4. client.models.generate_content_streamì„ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.\n",
    "        response_chunks = []\n",
    "        for chunk in client.models.generate_content_stream(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "        ):\n",
    "            response_chunks.append(chunk.text)\n",
    "        \n",
    "        return \"\".join(response_chunks)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return '{\"summary\": \"Error during analysis.\"}'\n",
    "\n",
    "\n",
    "# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df['summary'] = df['content'].apply(lambda content: analyze_news_article(content, api_key=API_KEY))\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "313b65f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title        publish_date  \\\n",
      "0  Renault set to name interim CEO next week, FT ... 2025-07-09 13:07:00   \n",
      "1  Trump has delayed his monster tariffs. Hereâ€™s ... 2025-07-09 13:01:00   \n",
      "2  AP Top Extended Financial Headlines at 12:48 a... 2025-07-09 13:00:00   \n",
      "3            AP Top Financial News at 12:48 a.m. EDT 2025-07-09 13:00:00   \n",
      "4  REUTERS NEXT-Markets becoming desensitised to ... 2025-07-09 12:17:00   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://finance.yahoo.com/news/renault-set-nam...   \n",
      "1  https://finance.yahoo.com/news/trump-delayed-m...   \n",
      "2  https://finance.yahoo.com/news/ap-top-extended...   \n",
      "3  https://finance.yahoo.com/news/ap-top-financia...   \n",
      "4  https://finance.yahoo.com/news/reuters-next-gl...   \n",
      "\n",
      "                                             content  \\\n",
      "0  (Reuters) -Renault will name an interim CEO ne...   \n",
      "1  Shipping containers at the port of Houston in ...   \n",
      "2  President Donald Trump has sent letters to 14 ...   \n",
      "3  A look at the countries that received Trump's ...   \n",
      "4  By Yantoultra Ngui, Jun Yuan Yong and Himanshi...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  Renault is preparing to name an interim CEO ne...   \n",
      "1  President Trump's \"reciprocal\" tariffs have be...   \n",
      "2  President Donald Trump has notified 14 countri...   \n",
      "3  To provide an expert analysis and a three-sent...   \n",
      "4  Global financial markets are reportedly becomi...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [0.022992134, -0.04607002, -0.008888895, -0.00...  \n",
      "1  [0.017440025, -0.029061683, -0.009535746, -0.0...  \n",
      "2  [0.023037886, -0.057103354, -0.038891286, -0.0...  \n",
      "3  [0.03301442, -0.001232819, -0.04580554, -0.020...  \n",
      "4  [0.0029243096, -0.014824337, -0.055987753, -0....  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google import genai\n",
    "import os\n",
    "\n",
    "# --- ì—¬ê¸°ì— API í‚¤ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš” ---\n",
    "API_KEY = \"AIzaSyDkYM__gE0UyegX2-6BUaxjj7PivCPchk8\" \n",
    "\n",
    "def get_summary_embedding(summary_text: str, client: genai.Client) -> list[float] | None:\n",
    "    \"\"\"\n",
    "    í•˜ë‚˜ì˜ ìš”ì•½ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì„ë² ë”© ë²¡í„°ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    # 1. ìš”ì•½ë³¸ ë‚´ìš©ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸\n",
    "    if not summary_text or pd.isna(summary_text):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 2. 'contents'ê°€ ì•„ë‹Œ 'content' íŒŒë¼ë¯¸í„°ë¡œ ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬\n",
    "        result = client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            contents=summary_text,\n",
    "            config=types.EmbedContentConfig(task_type=\"RETRIEVAL_DOCUMENT\")\n",
    "        )\n",
    "        # 3. ê²°ê³¼ ê°ì²´ì—ì„œ .embedding ì†ì„±ìœ¼ë¡œ ë²¡í„°ë¥¼ ì§ì ‘ ë°˜í™˜\n",
    "        vectors = [obj.values for obj in result.embeddings]\n",
    "        vectors=vectors[0]\n",
    "\n",
    "        return vectors\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API Error embedding '{summary_text[:50]}...': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # í´ë¼ì´ì–¸íŠ¸ëŠ” í•œ ë²ˆë§Œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    df['embedding'] = df['summary'].apply(lambda text: get_summary_embedding(text, client))\n",
    "\n",
    "    # ìµœì¢… ê²°ê³¼ í™•ì¸\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6895c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# 1. ì—¬ê¸°ì— ë³µì‚¬í•œ URLê³¼ Keyë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.\n",
    "supabase_url = \"https://hcmniqyaqybzhmzmaumh.supabase.co\"\n",
    "supabase_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImhjbW5pcXlhcXliemhtem1hdW1oIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTE0Mzk5NDgsImV4cCI6MjA2NzAxNTk0OH0.wj3P2BaI9_9LjXPULyKIYja20Xk3TbuqS916Sw83Pdg\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ba22075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜ï¸ Supabaseì— ì—°ê²°í•˜ì—¬ ê¸°ì¡´ ë°ì´í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
      "í˜„ì¬ DBì— 0ê°œì˜ ê¸°ì‚¬ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "âœ¨ 5ê°œì˜ ìƒˆë¡œìš´ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
      "ğŸ‰ ì„±ê³µì ìœ¼ë¡œ 5ê°œì˜ ìƒˆ ê¸°ì‚¬ë¥¼ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    supabase: Client = create_client(supabase_url, supabase_key)\n",
    "    print(\"â˜ï¸ Supabaseì— ì—°ê²°í•˜ì—¬ ê¸°ì¡´ ë°ì´í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # DBì— ì €ì¥ëœ ëª¨ë“  'title' ëª©ë¡ì„ ê°€ì ¸ì˜¤ê¸°\n",
    "    response = supabase.table('financial_news_summary').select('title').execute()\n",
    "    existing_titles = {item['title'] for item in response.data}\n",
    "    print(f\"í˜„ì¬ DBì— {len(existing_titles)}ê°œì˜ ê¸°ì‚¬ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ìƒˆë¡œ ìƒì„±ëœ DataFrameì—ì„œ ì´ë¯¸ ìˆëŠ” titleë“¤ì„ ì œì™¸\n",
    "    new_articles_df = df[~df['title'].isin(existing_titles)]\n",
    "\n",
    "    if new_articles_df.empty:\n",
    "        print(\"âœ… ì¶”ê°€í•  ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(f\"âœ¨ {len(new_articles_df)}ê°œì˜ ìƒˆë¡œìš´ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    \n",
    "        # ì—…ë¡œë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "        records_to_upload = new_articles_df.to_dict('records')\n",
    "        for record in records_to_upload:\n",
    "            record['publish_date'] = record['publish_date'].isoformat()\n",
    "        \n",
    "        # ë°ì´í„° ì‚½ì…\n",
    "        data, count = supabase.table('financial_news_summary').insert(records_to_upload).execute()\n",
    "        print(f\"ğŸ‰ ì„±ê³µì ìœ¼ë¡œ {len(data[1])}ê°œì˜ ìƒˆ ê¸°ì‚¬ë¥¼ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
