#################################
# 1. ì—°ê´€ ë‰´ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸

# RAGë¥¼ í†µí•´ ê¸°ì—… ì„¤ëª…ê³¼ ê´€ë ¨ëœ ë‰´ìŠ¤ 15ê°œë¥¼ 1ì°¨ ì¶”ì¶œ
# ì´í›„ Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ë‰´ìŠ¤ 3ê°œë¥¼ ì„ íƒí•œë‹¤
# ì´ ê²°ê³¼ëŠ” stateì˜ DomesticNews í´ë˜ìŠ¤ì— ì €ì¥ëœë‹¤.

import os
import json
import time
from typing import Dict, Any, List

# --- ì¶”ê°€ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
from dotenv import load_dotenv
from supabase import create_client, Client
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import ast
# -------------------------

from google import genai
from google.genai import types

# ìƒìœ„ í´ë”ì— ìˆëŠ” state.py ëª¨ë“ˆì—ì„œ AnalysisState í´ë˜ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from ..state import AnalysisState, DomesticNews

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
load_dotenv()

# --- Gemini API ì„¤ì • ---
# ë£¨íŠ¸í´ë”ì˜ .env íŒŒì¼ì— ì €ì¥í•œ Gemini ì ‘ì† ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.
API_KEY = os.environ.get("GEMINI_API_KEY_2")
if not API_KEY:
    raise EnvironmentError("GEMINI_API_KEYë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
# Gemini í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
client = genai.Client(api_key=API_KEY)



# Supabase ì ‘ì† ì •ë³´ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
url = os.getenv("SUPABASE_URL")
key = os.getenv("SUPABASE_KEY")

# ì ‘ì† ì •ë³´ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
if not all([url, key]):
    raise EnvironmentError("SUPABASE_URL ë° SUPABASE_KEYë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

# Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
supabase: Client = create_client(url, key)

# í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
print("Supabaseì—ì„œ ê¸°ì—… ë° ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
df_company = pd.DataFrame(supabase.table("company_summary").select("company_name,ticker, summary, summary_embedding").execute().data)
df_news = pd.DataFrame(supabase.table("ko_financial_news_summary").select("title, url, summary, embedding, publish_date").execute().data)
df_news['publish_date'] = pd.to_datetime(df_news['publish_date']).dt.strftime('%Y-%m-%d')

# ì„ë² ë”© ì»¬ëŸ¼(ë¬¸ìì—´)ì„ ì‹¤ì œ ë²¡í„°(Numpy ë°°ì—´)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
df_company['embedding_array'] = df_company['summary_embedding'].apply(lambda x: np.array(ast.literal_eval(x)))
df_news['embedding_array'] = df_news['embedding'].apply(lambda x: np.array(ast.literal_eval(x)))
print("ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì™„ë£Œ.")
# ---------------------------------------------

# --- ì‚¬ì „ ì •ì˜ëœ ì—”í‹°í‹° ë° ì§€í‘œ ë§¤í•‘ ---
# ê¸°ê³„ê°€ ì‚¬ìš©í•˜ëŠ” Ticker(Key)ì™€ ì‚¬ëŒì´ ì´í•´í•˜ëŠ” ì´ë¦„(Value)ì„ ëª…í™•íˆ ë¶„ë¦¬í•©ë‹ˆë‹¤.
# ì´ êµ¬ì¡°ë¥¼ í†µí•´ AIëŠ” ì‚¬ëŒì´ ì´í•´í•˜ëŠ” ì´ë¦„ìœ¼ë¡œ ì‘ì—…í•˜ê³ ,
# ì‹œìŠ¤í…œì€ Tickerë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ì˜ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

METRICS_MAP = {
    # === ì§€ìˆ˜ ===
    '^GSPC': {'name': 'S&P 500 ì§€ìˆ˜', "type": "index"},
    '^KS11': {'name': 'ì½”ìŠ¤í”¼ ì§€ìˆ˜', "type": "index"},
    'CL=F': {'name': 'WTI ì›ìœ  ì„ ë¬¼', "type": "index"},
    'USDKRW=X': {'name': 'ë‹¬ëŸ¬/ì› í™˜ìœ¨', "type": "index"},
    # === ë¯¸êµ­ ê¸°ì—… ===
    "NVDA": {
        "name": "NVIDIA",
        "type": "stock"
    },
    "MSFT": {
        "name": "Microsoft",
        "type": "stock"
    },
    "AAPL": {
        "name": "Apple",
        "type": "stock"
    },
    "AMZN": {
        "name": "Amazon",
        "type": "stock"
    },
    "GOOG": {
        "name": "Alphabet (Google)",
        "type": "stock"
    },
    "META": {
        "name": "Meta Platforms (Facebook)",
        "type": "stock"
    },
    "AVGO": {
        "name": "Broadcom",
        "type": "stock"
    },
    "BRK-B": {
        "name": "Berkshire Hathaway",
        "type": "stock"
    },
    "TSLA": {
        "name": "Tesla",
        "type": "stock"
    },
    "JPM": {
        "name": "JPMorgan Chase",
        "type": "stock"
    },
    "WMT": {
        "name": "Walmart",
        "type": "stock"
    },
    "V": {
        "name": "Visa",
        "type": "stock"
    },
    "LLY": {
        "name": "Eli Lilly",
        "type": "stock"
    },
    "ORCL": {
        "name": "Oracle",
        "type": "stock"
    },
    "NFLX": {
        "name": "Netflix",
        "type": "stock"
    },
    "MA": {
        "name": "Mastercard",
        "type": "stock"
    },
    "XOM": {
        "name": "Exxon Mobil",
        "type": "stock"
    },
    "COST": {
        "name": "Costco",
        "type": "stock"
    },
    "PG": {
        "name": "Procter & Gamble",
        "type": "stock"
    },
    "JNJ": {
        "name": "Johnson & Johnson",
        "type": "stock"
    },
    "HD": {
        "name": "Home Depot",
        "type": "stock"
    },
    "BAC": {
        "name": "Bank of America",
        "type": "stock"
    },
    "ABBV": {
        "name": "AbbVie",
        "type": "stock"
    },
    "PLTR": {
        "name": "Palantir",
        "type": "stock"
    },
    "KO": {
        "name": "Coca-Cola",
        "type": "stock"
    },
    "UNH": {
        "name": "UnitedHealth",
        "type": "stock"
    },
    "PM": {
        "name": "Philip Morris International",
        "type": "stock"
    },
    "CSCO": {
        "name": "Cisco",
        "type": "stock"
    },
    "TMUS": {
        "name": "T-Mobile US",
        "type": "stock"
    },
    "WFC": {
        "name": "Wells Fargo",
        "type": "stock"
    },
    "IBM": {
        "name": "IBM",
        "type": "stock"
    },
    "GE": {
        "name": "General Electric",
        "type": "stock"
    },
    "CRM": {
        "name": "Salesforce",
        "type": "stock"
    },
    "CVX": {
        "name": "Chevron",
        "type": "stock"
    },
    "ABT": {
        "name": "Abbott Laboratories",
        "type": "stock"
    },
    "MS": {
        "name": "Morgan Stanley",
        "type": "stock"
    },
    "AXP": {
        "name": "American Express",
        "type": "stock"
    },
    "AMD": {
        "name": "AMD",
        "type": "stock"
    },
    "DIS": {
        "name": "Walt Disney",
        "type": "stock"
    },
    "INTU": {
        "name": "Intuit",
        "type": "stock"
    },
    "NOW": {
        "name": "ServiceNow",
        "type": "stock"
    },
    "MCD": {
        "name": "McDonald",
        "type": "stock"
    },
    "T": {
        "name": "AT&T",
        "type": "stock"
    },
    "MRK": {
        "name": "Merck",
        "type": "stock"
    },
    "TXN": {
        "name": "Texas Instruments",
        "type": "stock"
    },
    "UBER": {
        "name": "Uber",
        "type": "stock"
    },
    "ISRG": {
        "name": "Intuitive Surgical",
        "type": "stock"
    },
    "RTX": {
        "name": "RTX",
        "type": "stock"
    },
    "BX": {
        "name": "Blackstone Group",
        "type": "stock"
    },
    "CAT": {
        "name": "Caterpillar",
        "type": "stock"
    },
    "BKNG": {
        "name": "Booking Holdings (Booking.com)",
        "type": "stock"
    },
    "PEP": {
        "name": "Pepsico",
        "type": "stock"
    },
    "VZ": {
        "name": "Verizon",
        "type": "stock"
    },
    "QCOM": {
        "name": "QUALCOMM",
        "type": "stock"
    },
    "BLK": {
        "name": "BlackRock",
        "type": "stock"
    },
    "SCHW": {
        "name": "Charles Schwab",
        "type": "stock"
    },
    "C": {
        "name": "Citigroup",
        "type": "stock"
    },
    "BA": {
        "name": "Boeing",
        "type": "stock"
    },
    "SPGI": {
        "name": "S&P Global",
        "type": "stock"
    },
    "TMO": {
        "name": "Thermo Fisher Scientific",
        "type": "stock"
    },
    "ADBE": {
        "name": "Adobe",
        "type": "stock"
    },
    "AMGN": {
        "name": "Amgen",
        "type": "stock"
    },
    "HON": {
        "name": "Honeywell",
        "type": "stock"
    },
    "BSX": {
        "name": "Boston Scientific",
        "type": "stock"
    },
    "PGR": {
        "name": "Progressive",
        "type": "stock"
    },
    "AMAT": {
        "name": "Applied Materials",
        "type": "stock"
    },
    "NEE": {
        "name": "Nextera Energy",
        "type": "stock"
    },
    "SYK": {
        "name": "Stryker Corporation",
        "type": "stock"
    },
    "DHR": {
        "name": "Danaher",
        "type": "stock"
    },
    "PFE": {
        "name": "Pfizer",
        "type": "stock"
    },
    "COF": {
        "name": "Capital One",
        "type": "stock"
    },
    "UNP": {
        "name": "Union Pacific Corporation",
        "type": "stock"
    },
    "GEV": {
        "name": "GE Vernova",
        "type": "stock"
    },
    "DE": {
        "name": "Deere & Company (John Deere)",
        "type": "stock"
    },
    "TJX": {
        "name": "TJX Companies",
        "type": "stock"
    },
    "GILD": {
        "name": "Gilead Sciences",
        "type": "stock"
    },
    "MU": {
        "name": "Micron Technology",
        "type": "stock"
    },
    "PANW": {
        "name": "Palo Alto Networks",
        "type": "stock"
    },
    "CMCSA": {
        "name": "Comcast",
        "type": "stock"
    },
    "ANET": {
        "name": "Arista Networks",
        "type": "stock"
    },
    "KKR": {
        "name": "KKR & Co.",
        "type": "stock"
    },
    "CRWD": {
        "name": "CrowdStrike",
        "type": "stock"
    },
    "LOW": {
        "name": "Lowe's Companies",
        "type": "stock"
    },
    "LRCX": {
        "name": "Lam Research",
        "type": "stock"
    },
    "ADP": {
        "name": "Automatic Data Processing",
        "type": "stock"
    },
    "KLAC": {
        "name": "KLA",
        "type": "stock"
    },
    "ADI": {
        "name": "Analog Devices",
        "type": "stock"
    },
    "APH": {
        "name": "Amphenol",
        "type": "stock"
    },
    "COP": {
        "name": "ConocoPhillips",
        "type": "stock"
    },
    "VRTX": {
        "name": "Vertex Pharmaceuticals",
        "type": "stock"
    },
    "APP": {
        "name": "AppLovin",
        "type": "stock"
    },
    "MSTR": {
        "name": "Strategy  (MicroStrategy)",
        "type": "stock"
    },
    "NKE": {
        "name": "Nike",
        "type": "stock"
    },
    "LMT": {
        "name": "Lockheed Martin",
        "type": "stock"
    },
    "SBUX": {
        "name": "Starbucks",
        "type": "stock"
    },
    "MMC": {
        "name": "Marsh & McLennan Companies",
        "type": "stock"
    },
    "ICE": {
        "name": "Intercontinental Exchange",
        "type": "stock"
    },
    "AMT": {
        "name": "American Tower",
        "type": "stock"
    },
    "DASH": {
        "name": "DoorDash",
        "type": "stock"
    }
}




# --- RAG í•¨ìˆ˜ ---
# 15ê°œì˜ ë‰´ìŠ¤ í›„ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ê°€ìƒ RAG í•¨ìˆ˜ì…ë‹ˆë‹¤.
############ ë¯¸ë¦¬ ìƒì„±í•œ ê²ƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
def search_relevant_news_rag(company_name: str) -> List[Dict[str, str]]:
    """
    Supabaseì— ì €ì¥ëœ ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬, íŠ¹ì • ê¸°ì—… ì„¤ëª…ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë‰´ìŠ¤ 15ê°œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ì´ë•Œ ê²€ìƒ‰ ëŒ€ìƒ ê¸°ì—…ì˜ í‹°ì»¤ë¥¼ ëª¨ë“  ë‰´ìŠ¤ ê²°ê³¼ì— í¬í•¨í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ” [News Analyst] Supabase ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ '{company_name}' ê´€ë ¨ ë‰´ìŠ¤ 15ê°œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

    try:
        # 1. ì „ì—­ df_company ë°ì´í„°í”„ë ˆì„ì—ì„œ ë¶„ì„í•  ê¸°ì—…ì˜ í–‰ì„ ì°¾ìŠµë‹ˆë‹¤.
        company_row = df_company[df_company['company_name'] == company_name]
        if company_row.empty:
            print(f"ê²½ê³ : DBì—ì„œ '{company_name}' ê¸°ì—… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # --- [ìˆ˜ì •ëœ ë¶€ë¶„ 1: í‹°ì»¤ ì •ë³´ ì¡°íšŒ] ---
        # 2. í•´ë‹¹ ê¸°ì—…ì˜ ì„ë² ë”© ë²¡í„°ì™€ 'í‹°ì»¤'ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        company_vec = company_row.iloc[0]['embedding_array'].reshape(1, -1)
        company_ticker = company_row.iloc[0]['ticker'] # ê²€ìƒ‰ ëŒ€ìƒ ê¸°ì—…ì˜ í‹°ì»¤ë¥¼ ë³€ìˆ˜ì— ì €ì¥
        # --- [ìˆ˜ì • ë] ---


        # 3. ì „ì²´ ë‰´ìŠ¤ì˜ ì„ë² ë”© ë²¡í„°ë“¤ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ í•œ ë²ˆì— ê³„ì‚°í•©ë‹ˆë‹¤.
        news_embeddings = np.vstack(df_news['embedding_array'].values)
        similarities = cosine_similarity(company_vec, news_embeddings)[0]

        # 4. ê³„ì‚°ëœ ìœ ì‚¬ë„ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ 15ê°œ ë‰´ìŠ¤ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        top_indices = similarities.argsort()[-15:][::-1]

        # 5. í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ë‰´ìŠ¤ ì •ë³´(ì œëª©, ìš”ì•½, URL ë“±)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        top_news_df = df_news.iloc[top_indices][['title', 'summary', 'url', 'publish_date']]

        # --- [ìˆ˜ì •ëœ ë¶€ë¶„ 2: ì¡°íšŒí•œ í‹°ì»¤ ì¶”ê°€] ---
        # 6. ê²€ìƒ‰ëœ ëª¨ë“  ë‰´ìŠ¤(DataFrame)ì— ê²€ìƒ‰ ëŒ€ìƒ ê¸°ì—…ì˜ í‹°ì»¤ë¥¼ ìƒˆë¡œìš´ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
        top_news_df['ticker'] = company_ticker
        # --- [ìˆ˜ì • ë] ---

        # 7. ê²°ê³¼ë¥¼ AIê°€ ì²˜ë¦¬í•˜ê¸° ì‰¬ìš´ List[Dict] í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        #    ì»¬ëŸ¼ ìˆœì„œë¥¼ ì¡°ì •í•˜ì—¬ tickerê°€ ì•ì— ì˜¤ê²Œ í•©ë‹ˆë‹¤.
        return top_news_df[['ticker', 'title', 'summary', 'url', 'publish_date']].to_dict('records')

    except Exception as e:
        print(f"RAG ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return []




# --- GEMINI ë‰´ìŠ¤ ì„ ì • í•¨ìˆ˜ ---
# RAGì˜ ê²°ê³¼ ì¤‘ ìµœì¢… 3ê°œ ì •ë„ë¥¼ geminië¡œ ì„ ë³„í•œë‹¤
# ë‰´ìŠ¤ ì œëª©ì´ ì•„ë‹ˆë¼ ë‰´ìŠ¤ ëª©ë¡ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ë„ë¡ í•œë‹¤.
# í”„ë¡¬í”„íŠ¸ì—ëŠ” ê¸°ì—…ëª… ë¿ë§Œì´ ì•„ë‹ˆë¼ ê¸°ì—…ì˜ ì„¤ëª…, ì—¬ëŸ¬ ì§€í‘œ ëª©ë¡ê³¼ ì´ì— ëŒ€ì‘ë˜ëŠ” tickerë“¤ì„ ë„£ì–´ì•¼ í•œë‹¤.
def select_top_news_with_gemini(
    company_name: str,
    company_description: str,
    news_list: List[Dict[str, str]],
    # us_entities_for_promptëŠ” ì´ì œ "ì´ë¦„ (í‹°ì»¤)" í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ìŠµë‹ˆë‹¤.
    us_entities_for_prompt: List[str]
) -> List[Dict[str, Any]]:
    """
    Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ 3ê°œë¥¼ ì„ ë³„í•˜ê³ , ê´€ë ¨ëœ ë¯¸êµ­ ê¸°ì—…/ì§€í‘œì˜ í‹°ì»¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    print("[News Analyst] Gemini AIë¥¼ í˜¸ì¶œí•˜ì—¬ 15ê°œ ë‰´ìŠ¤ ì¤‘ í•µì‹¬ ë‰´ìŠ¤ 3ê°œë¥¼ ì„ ë³„í•©ë‹ˆë‹¤.")

    # "ì´ë¦„ (í‹°ì»¤)" í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    entities_prompt_list = ", ".join(f'"{item}"' for item in us_entities_for_prompt)

    # --- [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ë¥¼ ì¢€ ë” ê°•í•˜ê³  ëª…í™•í•˜ê²Œ ìˆ˜ì •í•˜ì—¬ AIê°€ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ì•Šë„ë¡ ìœ ë„ ---
    prompt_parts = [
        f"You are a silent JSON-generating robot. Your sole purpose is to return a valid JSON object based on the instructions.",
        f"Analyze news about the target company ({company_name}) and connect it to a predefined list of US entities.",
        "\n### TARGET COMPANY INFORMATION ###",
        f"Company Name: {company_name}",
        f"Company Description: {company_description}",
        "\n### INSTRUCTIONS ###",
        "1. From the 'TARGET COMPANY NEWS LIST' below, select the 3 most impactful news articles.",
        "2. For EACH of the 3 selected news, identify 1-2 MOST relevant tickers from the 'US ENTITY LIST'. The ticker is inside the parentheses `()`. ",
        "3. **You MUST return your answer ONLY as a single, valid JSON object.**",
        "4. **DO NOT include any other text, explanation, or markdown like ```json. Your entire response must be ONLY the JSON object itself, starting with `{` and ending with `}`.**",
        "5. Can you extract as many Korea-related tickers as possible, like the USD/KRW exchange rate ('USDKRW=X') or the KOSPI index ('^KS11')?"
        "\n### US ENTITY LIST (Name (Ticker)) ###",
        # ì´ì œ "NVIDIA (NVDA)" ì™€ ê°™ì€ ëª…í™•í•œ ì •ë³´ê°€ AIì—ê²Œ ì œê³µë©ë‹ˆë‹¤.
        f"[{entities_prompt_list}]",
        "\n### OUTPUT FORMAT EXAMPLE ###",
        # ì˜ˆì‹œë¥¼ í†µí•´ AIê°€ ë°˜í™˜í•´ì•¼ í•  í˜•ì‹ì„ ë‹¤ì‹œ í•œë²ˆ ëª…í™•íˆ ë³´ì—¬ì¤ë‹ˆë‹¤.
        "{\"selected_domestic_news\": [{\"index\": 1, \"related_tickers\": [\"NVDA\"]}, {\"index\": 2, \"related_tickers\": [\"^NDX\", \"USDKRW=X\"]}, {\"index\": 8, \"related_tickers\": [\"MSFT\"]}]}",
        "\n--- TARGET COMPANY NEWS LIST ---\n"
    ]
    # --- [í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ë] ---

    # 15ê°œì˜ ë‰´ìŠ¤ í•­ëª©ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    for i, news in enumerate(news_list):
        # ì´ì œ news ë”•ì…”ë„ˆë¦¬ì— tickerê°€ ìˆì§€ë§Œ, AIì˜ í˜¼ë™ì„ ë§‰ê¸° ìœ„í•´ í”„ë¡¬í”„íŠ¸ì—ëŠ” ë„£ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        # AIëŠ” ì˜¤ì§ US ENTITY LISTì—ì„œë§Œ í‹°ì»¤ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.
        prompt_parts.append(f"[{i}] Title: {news['title']}\nSummary: {news['summary']}\n")
    prompt = "\n".join(prompt_parts)

    try:
        # API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        client = genai.Client(api_key=api_key)
        model = "gemini-2.5-flash"
        contents = [types.Content(role="user", parts=[types.Part.from_text(text=prompt)])] 
        
        # ì´ì „ ì˜ˆì‹œ ì½”ë“œì˜ generate_content_config í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤.
        generate_content_config = types.GenerateContentConfig(
            thinking_config = types.ThinkingConfig(
                thinking_budget=-1,
            ),
            tools=[
                types.Tool(googleSearch=types.GoogleSearch()), # ì˜ˆì‹œ ì½”ë“œì— í¬í•¨ëœ ë„êµ¬
            ],
            response_mime_type="text/plain", # JSONì„ í…ìŠ¤íŠ¸ë¡œ ë°›ìœ¼ë¯€ë¡œ plain text
        )

        # generate_content_stream í˜¸ì¶œë¡œ ë³€ê²½í•˜ê³  stream=True ì¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        response_stream = client.models.generate_content_stream( 
            model=model, 
            contents=contents, 
            config=generate_content_config,
        )

        response_text = ""
        for chunk in response_stream:
            response_text += chunk.text
            
        # --- [ì¶”ê°€] AIì˜ ì›ë³¸ ì‘ë‹µì„ í™•ì¸í•˜ê¸° ìœ„í•œ ë””ë²„ê¹… ì½”ë“œ ---
        print("\n" + "="*40)
        print(">>> Gemini API Raw Response (for Debugging) <<<")
        print(response_text)
        print("="*40 + "\n")
        # --- [ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€ ë] ---

        # --- [ìˆ˜ì •] JSON íŒŒì‹± ë¡œì§ì„ ë” ì•ˆì •ì ìœ¼ë¡œ ë³€ê²½í•˜ê³ , ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì—ëŸ¬ë¥¼ ì¶œë ¥ ---
        try:
            # ëª¨ë¸ì´ ì‘ë‹µ ì•ë’¤ì— ```json ... ``` ê°™ì€ ë§ˆí¬ë‹¤ìš´ì„ ë¶™ì´ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
            if '```json' in response_text:
                # ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ì´ ìˆë‹¤ë©´ ê·¸ ì•ˆì˜ ë‚´ìš©ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
                # rfindë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆì§€ë§‰ ```jsonì„ ì°¾ê³ , ê·¸ ì´í›„ ì²« ```ì„ ì°¾ìŠµë‹ˆë‹¤.
                start_marker = '```json'
                end_marker = '```'
                start_index = response_text.rfind(start_marker)
                
                if start_index != -1:
                    json_candidate = response_text[start_index + len(start_marker):]
                    end_index = json_candidate.find(end_marker)
                    if end_index != -1:
                        json_string = json_candidate[:end_index].strip()
                    else: # ë‹«ëŠ” ë§ˆí¬ë‹¤ìš´ì´ ì—†ëŠ” ê²½ìš°, ëê¹Œì§€ ì‚¬ìš©
                        json_string = json_candidate.strip()
                else: # ```json ë§ˆì»¤ê°€ ì—†ëŠ” ê²½ìš°
                    json_string = response_text.strip()
            else: # ë§ˆí¬ë‹¤ìš´ì´ ì—†ëŠ” ê²½ìš°, ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
                start_index = response_text.find('{')
                end_index = response_text.rfind('}') + 1
                if start_index != -1 and end_index > start_index:
                    json_string = response_text[start_index:end_index]
                else:
                    # ì‘ë‹µì—ì„œ JSON ê°ì²´ì˜ ì‹œì‘ê³¼ ëì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
                    raise ValueError("Could not find a valid JSON object structure in the response.")

            result = json.loads(json_string)
            
            # ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë§ëŠ”ì§€ í•œ ë²ˆ ë” í™•ì¸í•©ë‹ˆë‹¤.
            if 'selected_domestic_news' not in result or not isinstance(result['selected_domestic_news'], list):
                 raise ValueError("JSON is valid, but the 'selected_domestic_news' key is missing or not a list.")

            print(f"Geminiê°€ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±í•œ ë‰´ìŠ¤ ì •ë³´: {result['selected_domestic_news']}")
            return result['selected_domestic_news']

        except (json.JSONDecodeError, IndexError, ValueError) as e:
            # JSON íŒŒì‹± ê³¼ì •ì—ì„œ ì–´ë–¤ ì¢…ë¥˜ì˜ ì—ëŸ¬ê°€ ë°œìƒí–ˆëŠ”ì§€ ëª…í™•íˆ ì¶œë ¥í•©ë‹ˆë‹¤.
            print(f"!!! [ERROR] Failed to parse JSON from Gemini's response. Reason: {e}")
            # ì—¬ê¸°ì„œ ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ë°”ê¹¥ìª½ except ë¸”ë¡ì´ ë¹„ìƒ ëª¨ë“œë¥¼ ì‹¤í–‰í•˜ë„ë¡ í•©ë‹ˆë‹¤.
            raise
        # --- [íŒŒì‹± ë¡œì§ ìˆ˜ì • ë] ---

    except Exception as e:
        print(f"Gemini API í˜¸ì¶œ ë˜ëŠ” ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        fallback_result = [{"index": i, "related_tickers": []} for i in range(min(3, len(news_list)))]
        print(f"ë¹„ìƒ ëª¨ë“œ: ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ {len(fallback_result)}ê°œë¥¼ ì„ì‹œë¡œ ì„ íƒí•©ë‹ˆë‹¤.")
        return fallback_result


def run_domestic_news_analyst(state: AnalysisState) -> Dict[str, Any]:
    """
    ë‰´ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸ì˜ ì‹¤í–‰ í•¨ìˆ˜.
    RAGë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  Geminië¡œ í•µì‹¬ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ì—¬ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    print("\n---  ë‰´ìŠ¤ ë¶„ì„ ì—ì´ì „íŠ¸ ì‹¤í–‰ ---")
    company_name = state["company_name"] #ê¸°ì—… ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    company_description = state["company_description"] #ê¸°ì—… ì„¤ëª… ê°€ì ¸ì˜¤ê¸°

    # 1. RAGë¥¼ í†µí•´ ê´€ë ¨ ë‰´ìŠ¤ 15ê°œ ê²€ìƒ‰
    candidate_news = search_relevant_news_rag(company_name)
    if not candidate_news:
        return {"selected_domestic_news": []} # ê²€ìƒ‰ëœ ë‰´ìŠ¤ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    # 2. Gemini í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  ë¯¸êµ­ ê¸°ì—…/ì§€í‘œ ëª©ë¡ì„ "ì´ë¦„ (í‹°ì»¤)" í˜•ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    #    AIê°€ ì´ë¦„ê³¼ í‹°ì»¤ë¥¼ ëª…í™•í•˜ê²Œ ë§¤ì¹­í•  ìˆ˜ ìˆë„ë¡ ì •ë³´ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.
    #    ì˜ˆ: ["NVIDIA (NVDA)", "S&P 500 ì§€ìˆ˜ (^GSPC)", ...]
    us_entities_for_prompt = [f"{v['name']} ({k})" for k, v in METRICS_MAP.items()]
    # reverse_metrics_mapì€ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì‚­ì œí•˜ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
     # 3. Geminië¥¼ í†µí•´ ë‰´ìŠ¤ 3ê°œ ì„ ë³„ ë° ê´€ë ¨ ë¯¸êµ­ ê¸°ì—…/ì§€í‘œ Ticker ì¶”ì¶œ
    selected_domestic_news_data = select_top_news_with_gemini(
        company_name, company_description, candidate_news, us_entities_for_prompt
    )
    if not selected_domestic_news_data:
        print("[News Analyst] Geminië¡œë¶€í„° ìœ íš¨í•œ ë‰´ìŠ¤ ì„ íƒ ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return {"selected_domestic_news": []}
    
    # 4. Gemini ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë‰´ìŠ¤ ëª©ë¡ êµ¬ì„±
    final_news_list: List[DomesticNews] = []
    for news_info in selected_domestic_news_data:
        # Geminiê°€ ì•Œë ¤ì¤€ ì¸ë±ìŠ¤ì™€ Ticker ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        index = news_info.get("index")
        related_tickers = news_info.get("related_tickers", [])

        # Geminiê°€ ì˜ëª»ëœ ì¸ë±ìŠ¤ë¥¼ ì£¼ì—ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜
        if index is None or not (0 <= index < len(candidate_news)):
            continue
        
        # ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•´ RAGê°€ ì°¾ì•˜ë˜ ì›ë³¸ ë‰´ìŠ¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        news_item = candidate_news[index]
        
        # Ticker ëª©ë¡ì— í•´ë‹¹í•˜ëŠ” 'ì´ë¦„' ëª©ë¡ì„ ì°¾ìŠµë‹ˆë‹¤.
        # state.pyì˜ DomesticNews í´ë˜ìŠ¤ëŠ” 'entities' í•„ë“œì— ì´ë¦„ ëª©ë¡ì„ ìš”êµ¬í•©ë‹ˆë‹¤.
        entity_names = [v['name'] for k, v in METRICS_MAP.items() if k in related_tickers]

        # ìµœì¢… í˜•ì‹ì¸ DomesticNews ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        selected_domestic_news_item: DomesticNews = {
            "title": news_item["title"],
            "url": news_item["url"],
            "summary": news_item["summary"],
            "publish_date": news_item["publish_date"],
            "entities": entity_names,
            "related_metrics": related_tickers,
        }
        final_news_list.append(selected_domestic_news_item)
        print(f"  - ë‰´ìŠ¤ ì„ ë³„: \"{news_item['title']}\" (ì—°ê´€ Ticker: {related_tickers})")

    return {"selected_domestic_news": final_news_list}
